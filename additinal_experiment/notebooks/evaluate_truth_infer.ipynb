{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf30426",
   "metadata": {},
   "source": [
    "## Evaluate CATD, LFC, PM-CRH, ZC, LA, and Minmax\n",
    "Please place the file containing the aggregated results data in the appropriate location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620411c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(f\"../../main_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fadbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io_utils import get_accuracy, get_recall, load_dataset_profile, load_gt, load_human_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ee63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp=[0,5,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c2dd1-c932-4732-9e28-47a7bd175025",
   "metadata": {},
   "source": [
    "## Pre-step: Transform Minmax Results\n",
    "Please place the Minmax results in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38a597-b4b8-445e-9f11-08a67cd5e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_ai in sp:\n",
    "    for iter in range(5):\n",
    "        df = pl.read_csv(f\"result_{num_ai}_{iter+1}.csv\", has_header=False, dtypes=[pl.Utf8],\n",
    "                         new_columns=[\"task\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"])\n",
    "        df = df.with_columns(\n",
    "            max_val = pl.max_horizontal([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"])\n",
    "        ).with_columns(\n",
    "            label = (\n",
    "                pl.when(pl.col(\"1\") == pl.col(\"max_val\")).then(pl.lit(\"0\"))\n",
    "                .when(pl.col(\"2\") == pl.col(\"max_val\")).then(pl.lit(\"1\"))\n",
    "                .when(pl.col(\"3\") == pl.col(\"max_val\")).then(pl.lit(\"2\"))\n",
    "                .when(pl.col(\"4\") == pl.col(\"max_val\")).then(pl.lit(\"3\"))\n",
    "                .when(pl.col(\"5\") == pl.col(\"max_val\")).then(pl.lit(\"4\"))\n",
    "                .otherwise(pl.lit(\"5\"))\n",
    "            )\n",
    "        ).drop(\"max_val\")\n",
    "        df = df.select([\"task\",\"label\"])\n",
    "        df.write_csv(f\"../scripts/results/minmax_AI={num_ai}_{iter}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec35d1-ceb2-42d9-b049-e8475690bc49",
   "metadata": {},
   "source": [
    "## Main-step: Get Scores\n",
    "Please put the results data in `scripts/results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a327f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.read_csv(\"../human_responses_with_gt.csv\")\n",
    "gt = human_df.filter([\"task\",\"gt\"]).drop_duplicates(keep='last')\n",
    "biased_tasks = gt[gt[\"gt\"]==4][\"task\"].unique()  \n",
    "gt = gt.set_index(\"task\")\n",
    "human_df = human_df.drop([\"gt\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf2f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = [\n",
    "    \"CATD\", \"LA1\", \"LA2\", \"LFC\", \"minmax\", \"PM-CRH\", \"ZC\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4def7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record(num_ai, iter, method, acc, biased_acc):\n",
    "    return {\n",
    "        \"num_ai\": num_ai,\n",
    "        \"iteration\": iter,\n",
    "        \"method\": method,\n",
    "        \"accuracy\": acc,\n",
    "        \"recall\": biased_acc,\n",
    "    }\n",
    "\n",
    "records = []\n",
    "for num_ai in sp:\n",
    "    print(f\"=== {num_ai} AI Workers ===\")\n",
    "    for iter in range(5):\n",
    "        for name in METHODS:\n",
    "            print(f\"--- {name} ---\")\n",
    "            ret = pl.read_csv(f\"../scripts/results/{name}_AI={num_ai}_{iter}.csv\")\n",
    "            ret  = ret.select([\"task\", \"label\"]).to_pandas().set_index(\"task\")\n",
    "            \n",
    "            acc = get_accuracy(gt, ret)\n",
    "            biased_acc = get_recall(gt, ret, biased_tasks)\n",
    "            print(f\"Accuracy: {acc}, Recall: {biased_acc}\")\n",
    "            record = get_record(num_ai, iter, name, acc, biased_acc)\n",
    "            records.append(record)\n",
    "result_df = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e854a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"truth_infer_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85227999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
